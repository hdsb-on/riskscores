---
title: "Risk Score Vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Risk Score Vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

library(knitr)
library(tidyverse)

```




## Introduction 

Risk scores are sparse linear models that map an integer linear combination of covariates to the probability of an outcome occurring. Unlike regression models, risk score models consist of integer coefficients for often dichotomous variables. This allows risk score predictions to be easily computed by adding or subtracting a few small numbers. 

Risk scores developed heuristically by altering logistic regression models have decreased performance, as there is a fundamental trade-off between the model's simplicity and its predictive accuracy. In contrast, this package presents an optimization approach to learning risk scores, where the constraints unique to risk score models are integrated into the model-fitting process, rather than implemented afterward. This vignette demonstrates how to use the `riskscore` package to build a risk score model to predict breast cancer diagnosis. 

```{r setup}
library(riskscores)
```

## Optimization Problem

The `riskscore` package uses a cyclical coordinate descent algorithm to solve the following optimization problem.

\begin{equation}
\begin{aligned}
\min_{\alpha,\beta} \quad & \frac{1}{n} \sum_{i=1}^{n} (\gamma y_i x_i^T \beta - log(1 + exp(\gamma x_i^T \beta))) + \lambda_0 \sum_{j=1}^{p} 1(\beta_{j} \neq 0)\\
\textrm{s.t.} \quad & l \le \beta_j \le u \; \; \; \forall j = 1,2,...,p\\
  &\beta_j \in \mathbb{Z} \; \; \; \forall j = 1,2,...,p \\
  &\beta_0, \gamma \in \mathbb{R} \\
\end{aligned}
\end{equation}

These constraints ensure that the model will be sparse and include only integer coefficients. 

## Loading Example Data

First we'll load in an example dataset. In this example, we want to develop a risk score model that predicts whether a breast tissue sample is benign using features recorded during a biopsy. The `breastcancer` dataset was originally accessed from the [UCI Repository](https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original) and can be loaded into your environment from the `riskscore` package as so: 

```{r, eval = FALSE}
data("breastcancer")

```

This dataset contains 683 observations and 9 features. Our goal is to develop a risk score model that predicts whether a breast tissue sample is benign using 9 (or fewer) features recorded during a biopsy: \

1. Clump thickness \
2. Uniformity of cell size \
3. Uniformity of cell shape \
4. Marginal adhesion \
5. Single epithelial cell size \
6. Bare nuclei \
7. Bland chromatin \
8. Normal nucleoli \
9. Mitoses \


## Data Preprocessing

Before building a risk score model, data often need to be preprocessed. Specifically, the dataset needs to have a binary outcome with all other variables containing either binary or integer values. 

The `breastcancer` dataset has already been preprocessed. However, we'll still need to split out our data into a matrix with all covariates (`X`) and a vector with the outcome data (`y`). In this case, the first column in our dataset contains the outcome variable (`benign`). We also add to `X` a column representing the intercept (i.e. a column containing all 1s).

 



```{r}
y <- breastcancer[[1]]
X <- as.matrix(breastcancer[,2:ncol(breastcancer)])
X <- cbind(rep(1,nrow(X)), X) # add intercept column
```

## Cross Validation

The penalty coefficient $\lambda_0$ controls the sparsity of the model -- a larger value of $\lambda_0$ will result in fewer non-zero coefficients. We can use cross validation to find the optimal $\lambda_0$ value that creates a sufficiently sparse model without sacrificing performance. 

The `cv_risk_mod()` runs cross validation for a grid of possible $\lambda_0$ values. If the user does not specify the vector of $\lambda_0$ values to test, the program constructs this $\lambda_0$ sequence. The maximum $\lambda_0$ tested is the smallest value such that all coefficients are zero. The minimum $\lambda_0$ value is calculated using the user-defined `lambda_ratio` argument. The $\lambda_0$ sequence is created by generating `nlambda` values linear on the log scale from the minimum $\lambda_0$ to the maximum $\lambda_0$. We've set `nlambda` to 25, so the program will construct an appropriate sequence of 25 $\lambda_0$ values to test using cross validation. 

```{r}
cv_results <- cv_risk_mod(X, y, nfolds = 5, nlambda = 25, seed = 1)
```



Running `plot()` on a `cv_risk_mod` object creates a plot of mean deviance for each $\lambda_0$ value. The number of nonzero coefficients that are produced by each $\lambda_0$ value when fit on the full data are listed at the top of the plot. The $\lambda_0$ value with the lowest mean deviance ("lambda_min") is indicated in red, and its standard deviation is marked with a red dashed line.  In our example, the $\lambda_0$ that resulted in the lowest mean deviance creates a model with 7 nonzero coefficients. Its precise value can be accessed by calling `cv_results$lambda_min`. If we want a sparser model, we could increase $\lambda_0$ to "lambda_1se", the largest value whose mean deviance is within one standard error of "lambda_min". This value can be accessed by calling `cv_results$lambda_1se`. 

```{r, fig.width = 5, fig.height = 3, dpi = 125}
plot(cv_results)
```

To view a dataframe with the full cross-validation results (including both deviance and accuracy metrics), run `cv_results$results`.  


## Fit Risk Score Model

We'll fit a model on the full data using the function `risk_mod()`. We'll use the "lambda_min" value determined by cross-validation as our $\lambda_0$ parameter.  

```{r}
mod <- risk_mod(X, y, lambda0 = cv_results$lambda_min)

```

The integer risk score model can be viewed by calling `mod$model_card`. The risk score can be calculated by multiplying each covariate value by its respective number of points and then adding points together. 

```{r, echo = FALSE}
mod$model_card %>%
  kable(caption = "`mod$model_card`")
```

Each score can then be mapped to a risk probability. The `mod$score_map` data frame maps an integer range of scores to their associated risk. For this example dataset, `mod$score_map` includes a range of integer scores from 51 to 510, which are the minimum and maximum scores possible with this model. The table below shows a sample of these scores. 

```{r, echo = FALSE}
mod$score_map %>%
  filter(Score %in% seq(50, 300, 50)) %>%
  kable(caption = "`mod$score_map`")
```

The relationship between the scores and their associated risks can be visualized by plotting `mod$score_map`. 

```{r, fig.width = 5, fig.height = 3, dpi = 125}
plot(mod$score_map, type = "l")
```

A `glm` object for this logistic regression equation can be called using `mod$glm_mod`. Equivalently, the logistic regression coefficients can be calculated directly from the risk score model by multiplying the risk score coefficients (`mod$beta`) by the $\gamma$ value (`mod$gamma`). 

```{r}
coef(mod$glm_mod)


mod$beta * mod$gamma

```



Running `summary()` on our model will return the intercept, the scores of each nonzero coefficient, the $\gamma$ multiplier value, the $\lambda_0$ regularizer value, the deviance, and the AIC.

```{r}
summary(mod)
```

Other generic functions that can be called on `risk_mod` objects include `coef()` and `predict()`. In addition to the typical options for the `type` parameter of "link" and "response", running `predict()` on a `risk_mod` object also includes the option of "score", which returns each subject's risk score. 

The table below compares the three possible outputs from `predict()` for ten example subjects. The first seven columns contain data for clump thickness, uniformity of cell shape, marginal adhesion, bare nuclei, bland chromatin, normal nucleoli, and mitosis. 

```{r, echo = FALSE}


link <- predict(mod, type = "link")[1:5] %>%
  round(2)
response <- predict(mod, type = "response")[1:5] %>%
  round(3)
score <- predict(mod, type = "score")[1:5]

data.frame(X[1:5,which(dimnames(X)[[2]] %in% c("ClumpThickness",
                                             "UniformityOfCellShape",
                                             "MarginalAdhesion", "BareNuclei",
                                             "BlandChromatin", "NormalNucleoli",
                                             "Mitoses"))],
                       score, link, response) %>%
  kable(col.names = c("CT", "USC", "MA", "BN", "BC", "NN", "M",
                     "Score", "Link", "Response"),
        caption = "Score, Link, and Response Values for 5 Example Observations")

```

The "score" is a linear combination of the covariates: 
$$score = 10(CT) + 6(USC) + 6(MA) + 7(BN) + 8(BC) + 4(NN) + 10(M)$$


The "link" uses the associated logistic regression equation:
$$link = -10.04 + 0.56(CT) + 0.33(UCS) + 0.34(MA) + 0.39(BN) + 0.45(BC) + 0.22(NN) + 0.56(M)$$

The "response" converts these link values to probabilities: $$response = e^{link}/(1+e^{link})$$. 






